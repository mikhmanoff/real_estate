# parser_v2.py
"""
–ü–∞—Ä—Å–µ—Ä –æ–±—ä—è–≤–ª–µ–Ω–∏–π –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –∏–∑ Telegram –∫–∞–Ω–∞–ª–æ–≤ –¢–∞—à–∫–µ–Ω—Ç–∞.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π –∏ —É–∑–±–µ–∫—Å–∫–∏–π —è–∑—ã–∫–∏, –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤.
"""
import re
from typing import Optional, List, Dict, Any, Tuple
from dataclasses import dataclass, field, asdict


# ============================================
# DISTRICTS & METRO DATA
# ============================================

DISTRICTS = {
    # –ù–∞–∑–≤–∞–Ω–∏–µ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ -> –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
    "–º–∏—Ä–∑–æ —É–ª—É–≥–±–µ–∫": "–ú–∏—Ä–∑–æ-–£–ª—É–≥–±–µ–∫—Å–∫–∏–π",
    "–º–∏—Ä–∑–æ-—É–ª—É–≥–±–µ–∫": "–ú–∏—Ä–∑–æ-–£–ª—É–≥–±–µ–∫—Å–∫–∏–π",
    "–º–∏—Ä–∑–æ_—É–ª—É–≥–±–µ–∫": "–ú–∏—Ä–∑–æ-–£–ª—É–≥–±–µ–∫—Å–∫–∏–π",
    "–º–∏—Ä–∑–æ—É–ª—É–≥–±–µ–∫": "–ú–∏—Ä–∑–æ-–£–ª—É–≥–±–µ–∫—Å–∫–∏–π",
    "–º–∏—Ä–∑–æ —É–ª—É–≥–±–µ–∫—Å–∫–∏–π": "–ú–∏—Ä–∑–æ-–£–ª—É–≥–±–µ–∫—Å–∫–∏–π",
    "mirzo ulug'bek": "–ú–∏—Ä–∑–æ-–£–ª—É–≥–±–µ–∫—Å–∫–∏–π",
    
    "—é–Ω—É—Å–∞–±–∞–¥": "–Æ–Ω—É—Å–∞–±–∞–¥—Å–∫–∏–π",
    "—é–Ω—É—Å –∞–±–∞–¥": "–Æ–Ω—É—Å–∞–±–∞–¥—Å–∫–∏–π",
    "—é–Ω—É—Å–∞–±–∞–¥—Å–∫–∏–π": "–Æ–Ω—É—Å–∞–±–∞–¥—Å–∫–∏–π",
    "yunusabad": "–Æ–Ω—É—Å–∞–±–∞–¥—Å–∫–∏–π",
    
    "—á–∏–ª–∞–Ω–∑–∞—Ä": "–ß–∏–ª–∞–Ω–∑–∞—Ä—Å–∫–∏–π",
    "—á–∏–ª–∞–Ω–∑–∞—Ä—Å–∫–∏–π": "–ß–∏–ª–∞–Ω–∑–∞—Ä—Å–∫–∏–π",
    "chilanzar": "–ß–∏–ª–∞–Ω–∑–∞—Ä—Å–∫–∏–π",
    
    "–º–∏—Ä–∞–±–∞–¥": "–ú–∏—Ä–∞–±–∞–¥—Å–∫–∏–π",
    "–º–∏—Ä–∞–±–∞–¥—Å–∫–∏–π": "–ú–∏—Ä–∞–±–∞–¥—Å–∫–∏–π",
    "mirabad": "–ú–∏—Ä–∞–±–∞–¥—Å–∫–∏–π",
    
    "—è–∫–∫–∞—Å–∞—Ä–∞–π": "–Ø–∫–∫–∞—Å–∞—Ä–∞–π—Å–∫–∏–π",
    "—è–∫–∫–∞—Å–∞—Ä–∞–π—Å–∫–∏–π": "–Ø–∫–∫–∞—Å–∞—Ä–∞–π—Å–∫–∏–π",
    "yakkasaroy": "–Ø–∫–∫–∞—Å–∞—Ä–∞–π—Å–∫–∏–π",
    
    "—Å–µ—Ä–≥–µ–ª–∏": "–°–µ—Ä–≥–µ–ª–∏–π—Å–∫–∏–π",
    "—Å–µ—Ä–≥–µ–ª–∏–π—Å–∫–∏–π": "–°–µ—Ä–≥–µ–ª–∏–π—Å–∫–∏–π",
    "sergeli": "–°–µ—Ä–≥–µ–ª–∏–π—Å–∫–∏–π",
    
    "—à–∞–π—Ö–∞–Ω—Ç–∞—Ö—É—Ä": "–®–∞–π—Ö–∞–Ω—Ç–∞—Ö—É—Ä—Å–∫–∏–π",
    "—à–∞–π—Ö–æ–Ω—Ç–æ–≥—É—Ä": "–®–∞–π—Ö–∞–Ω—Ç–∞—Ö—É—Ä—Å–∫–∏–π",
    "—à–∞–π—Ö–∞–Ω—Ç–∞—Ö—É—Ä—Å–∫–∏–π": "–®–∞–π—Ö–∞–Ω—Ç–∞—Ö—É—Ä—Å–∫–∏–π",
    "shayxontohur": "–®–∞–π—Ö–∞–Ω—Ç–∞—Ö—É—Ä—Å–∫–∏–π",
    
    "–∞–ª–º–∞–∑–∞—Ä": "–ê–ª–º–∞–∑–∞—Ä—Å–∫–∏–π",
    "–∞–ª–º–∞–∑–∞—Ä—Å–∫–∏–π": "–ê–ª–º–∞–∑–∞—Ä—Å–∫–∏–π",
    "olmazar": "–ê–ª–º–∞–∑–∞—Ä—Å–∫–∏–π",
    
    "–±–µ–∫—Ç–µ–º–∏—Ä": "–ë–µ–∫—Ç–µ–º–∏—Ä—Å–∫–∏–π",
    "–±–µ–∫—Ç–µ–º–∏—Ä—Å–∫–∏–π": "–ë–µ–∫—Ç–µ–º–∏—Ä—Å–∫–∏–π",
    "bektemir": "–ë–µ–∫—Ç–µ–º–∏—Ä—Å–∫–∏–π",
    
    "—è—à–Ω–∞–±–∞–¥": "–Ø—à–Ω–∞–±–∞–¥—Å–∫–∏–π",
    "—è—à–Ω–æ–±–∞–¥": "–Ø—à–Ω–∞–±–∞–¥—Å–∫–∏–π",
    "—è—à–Ω–∞–±–∞–¥—Å–∫–∏–π": "–Ø—à–Ω–∞–±–∞–¥—Å–∫–∏–π",
    "yashnabad": "–Ø—à–Ω–∞–±–∞–¥—Å–∫–∏–π",
    
    "—É—á—Ç–µ–ø–∞": "–£—á—Ç–µ–ø–∏–Ω—Å–∫–∏–π",
    "—É—á—Ç–µ–ø–∏–Ω—Å–∫–∏–π": "–£—á—Ç–µ–ø–∏–Ω—Å–∫–∏–π",
    "uchtepa": "–£—á—Ç–µ–ø–∏–Ω—Å–∫–∏–π",
    
    "—Ü-1": "–ú–∏—Ä–∑–æ-–£–ª—É–≥–±–µ–∫—Å–∫–∏–π",  # –¶-1 —ç—Ç–æ —Ä–∞–π–æ–Ω –≤ –ú–∏—Ä–∑–æ-–£–ª—É–≥–±–µ–∫–µ
}

METRO_STATIONS = {
    "–º–∏–Ω–æ—Ä": "–ú–∏–Ω–æ—Ä",
    "minor": "–ú–∏–Ω–æ—Ä",
    "–æ–π–±–µ–∫": "–û–π–±–µ–∫",
    "oybek": "–û–π–±–µ–∫",
    "–ø—É—à–∫–∏–Ω": "–ü—É—à–∫–∏–Ω—Å–∫–∞—è",
    "–∫–æ—Å–º–æ–Ω–∞–≤—Ç–æ–≤": "–ö–æ—Å–º–æ–Ω–∞–≤—Ç–ª–∞—Ä",
    "—Ö–∞–º–∏–¥ –æ–ª–∏–º–∂–æ–Ω": "–•–∞–º–∏–¥–∞ –û–ª–∏–º–∂–æ–Ω–∞",
    "–±—É—é–∫ –∏–ø–∞–∫ –π—É–ª–∏": "–ë—É—é–∫ –ò–ø–∞–∫ –ô—û–ª–∏",
    "buyuk ipak yo'li": "–ë—É—é–∫ –ò–ø–∞–∫ –ô—û–ª–∏",
    "–º–∏–ª–∏–π –±–æ–≥": "–ú–∏–ª–ª–∏–π –ë–æ“ì",
    "milliy bog": "–ú–∏–ª–ª–∏–π –ë–æ“ì",
    "—Ç—É–∑–µ–ª—å": "–¢—É–∑–µ–ª",
    "tuzel": "–¢—É–∑–µ–ª",
    "—Å–µ—Ä–≥–µ–ª–∏": "–°–µ—Ä–≥–µ–ª–∏",
    "sergeli": "–°–µ—Ä–≥–µ–ª–∏",
    "—á–∫–∞–ª–æ–≤": "–ß–∫–∞–ª–æ–≤",
}

LANDMARKS = [
    "it park", "–∏—Ç –ø–∞—Ä–∫",
    "tata", "—Ç–∞—Ç–∞",
    "–º–µ–≥–∞–ø–ª–∞–Ω–µ—Ç", "megaplanet",
    "hi-tech", "—Ö–∞–π-—Ç–µ–∫",
    "–ø–∞—Ä–∫–µ–Ω—Ç—Å–∫–∏–π", "parkent",
    "–∞—Å—Å–∞–ª–æ–º —Å–æ—Ö–∏–ª", "assalom sohil",
    "akay city", "–∞–∫–∞–π —Å–∏—Ç–∏",
    "imperial club", "–∏–º–ø–µ—Ä–∏–∞–ª –∫–ª—É–±",
    "mirabad avenue",
    "prestige gardens",
    "solaris", "—Å–æ–ª—è—Ä–∏—Å",
]


# ============================================
# REGEX PATTERNS
# ============================================

# –¢–µ–ª–µ—Ñ–æ–Ω—ã - —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
PHONE_PATTERNS = [
    re.compile(r'\+998[\s\-]?\d{2}[\s\-]?\d{3}[\s\-]?\d{2}[\s\-]?\d{2}'),
    re.compile(r'\+998\d{9}'),
    re.compile(r'998\d{9}'),
    re.compile(r'\d{2}[\s\-]?\d{3}[\s\-]?\d{2}[\s\-]?\d{2}'),  # 90 123 45 67
]

# –§–æ—Ä–º–∞—Ç –∫–æ–º–Ω–∞—Ç—ã/—ç—Ç–∞–∂/—ç—Ç–∞–∂–Ω–æ—Å—Ç—å: 1/4/4, 2/3/9
TRIPLE_FORMAT = re.compile(r'[‚ö´üü†üî¥\s]*(\d+)\s*/\s*(\d+)\s*/\s*(\d+)[‚ö´üü†üî¥\s]*')

# –ö–æ–º–Ω–∞—Ç—ã - —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
ROOMS_PATTERNS = [
    # "–ö–æ–º–Ω–∞—Ç: 2", "–ö–æ–º–Ω–∞—Ç-2", "üè° –ö–æ–º–Ω–∞—Ç: 1"
    re.compile(r'(?:üè°\s*)?–∫–æ–º–Ω–∞—Ç[–∞—ã]?\s*[:\-‚Äì]\s*(\d+)', re.I),
    # "–ö–æ–ª.–ö–æ–º–Ω–∞—Ç:2", "–ö–æ–ª-–≤–æ –∫–æ–º–Ω–∞—Ç: 1"
    re.compile(r'–∫–æ–ª[\.\-]?\s*(?:–≤–æ\s+)?–∫–æ–º–Ω–∞—Ç\s*[:\-‚Äì]\s*(\d+)', re.I),
    # "2 –∫–æ–º–Ω–∞—Ç–Ω–∞—è", "1-–∫–æ–º–Ω–∞—Ç–Ω–∞—è"
    re.compile(r'(\d+)\s*[‚Äì\-]?\s*–∫–æ–º–Ω–∞—Ç(?:–Ω–∞—è|–∫–∞)', re.I),
    # –£–∑–±–µ–∫—Å–∫–∏–π: "Xonalar soni: 2", "2 XONA"
    re.compile(r'xonalar?\s*(?:soni)?\s*[:\-‚Äì]?\s*(\d+)', re.I),
    re.compile(r'(\d+)\s*xona', re.I),
    # "üîπ–ö–æ–º–Ω–∞—Ç: 2", "üî∏–ö–æ–º–Ω–∞—Ç: 2"
    re.compile(r'[üîπüî∏üíÆ]\s*–∫–æ–º–Ω–∞—Ç[–∞—ã]?\s*[:\-‚Äì]?\s*(\d+)', re.I),
]

# –≠—Ç–∞–∂
FLOOR_PATTERNS = [
    re.compile(r'(?:üîº|‚ô¶Ô∏è|üî∏|üîπ|üíÆ)?\s*—ç—Ç–∞–∂\s*[:\-‚Äì]?\s*(\d+)', re.I),
    re.compile(r'(\d+)\s*—ç—Ç–∞–∂(?!–Ω)', re.I),
    re.compile(r'qavat\s*[:\-‚Äì]?\s*(\d+)', re.I),
]

# –≠—Ç–∞–∂–Ω–æ—Å—Ç—å
TOTAL_FLOORS_PATTERNS = [
    re.compile(r'(?:‚è´|üî∏|üîπ|üíÆ)?\s*—ç—Ç–∞–∂–Ω–æ—Å—Ç[—å–∏]\s*[:\-‚Äì]?\s*(\d+)', re.I),
    re.compile(r'—ç—Ç–∞–∂–µ–π\s*(?:–≤\s*–¥–æ–º–µ)?\s*[:\-‚Äì]?\s*(\d+)', re.I),
    re.compile(r'(\d+)\s*[‚Äì\-]?\s*—ç—Ç–∞–∂–Ω(?:—ã–π|–∞—è|–æ–µ|–æ—Å—Ç—å)', re.I),
]

# –ü–ª–æ—â–∞–¥—å
AREA_PATTERNS = [
    re.compile(r'(?:üìê|üîé)?\s*(?:–æ–±—â–∞—è\s+)?–ø–ª–æ—â–∞–¥[—å–∏—è]\s*[:\-‚Äì]?\s*(\d+(?:[.,]\d+)?)\s*(?:–∫–≤\.?\s*–º(?:–µ—Ç—Ä)?|–º[¬≤2]?)?', re.I),
    re.compile(r'(\d+(?:[.,]\d+)?)\s*(?:–∫–≤\.?\s*–º|–º[¬≤2])', re.I),
    re.compile(r'–ø–ª–æ—â–∞–¥[—å–∏—è]\s*(\d+)\s*–∫–≤', re.I),
]

# –¶–µ–Ω–∞ - –º–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤
PRICE_PATTERNS = [
    # "–¶–µ–Ω–∞: 700", "üí∏ –¶–µ–Ω–∞: 600", "–¶–µ–Ω–∞ -700"
    re.compile(r'(?:üí∏|üí∞)?\s*(?:—Ü–µ–Ω–∞|narx)\s*[:\-‚Äì]?\s*(\d[\d\s]*)\s*(\$|y\.?e\.?|—É–µ|–¥–æ–ª–ª|—Å—É–º)?', re.I),
    # "700$", "600 $", "500y.e"
    re.compile(r'(\d{3,})\s*(\$|y\.?e\.?|—É–µ|–¥–æ–ª–ª)', re.I),
    # "350$+300$ –î–µ–ø–æ–∑–∏—Ç" - –±–µ—Ä—ë–º –ø–µ—Ä–≤—É—é —Ü–µ–Ω—É
    re.compile(r'(\d{3,})\s*\$\s*\+', re.I),
    # –£–∑–±–µ–∫—Å–∫–∏–π "Narx: 350 $"
    re.compile(r'narx\s*[:\-‚Äì]?\s*(\d+)\s*(\$|so\'?m|—Å—É–º)?', re.I),
]

# –î–µ–ø–æ–∑–∏—Ç
DEPOSIT_PATTERNS = [
    # "+300$ –î–µ–ø–æ–∑–∏—Ç", "–î–µ–ø–æ–∑–∏—Ç 300$"
    re.compile(r'\+\s*(\d+)\s*\$?\s*–¥–µ–ø–æ–∑–∏—Ç', re.I),
    re.compile(r'–¥–µ–ø–æ–∑–∏—Ç\s*[:\-‚Äì]?\s*(\d+)\s*\$?', re.I),
    # "–î–µ–ø–æ–∑–∏—Ç 50$", "–î–µ–ø–æ–∑–∏—Ç: 250$"
    re.compile(r'–¥–µ–ø–æ–∑–∏—Ç\s+(\d+)', re.I),
    # "|–î–µ–ø–æ–∑–∏—Ç 250$|"
    re.compile(r'\|–¥–µ–ø–æ–∑–∏—Ç\s*(\d+)', re.I),
]

# –ü—Ä–æ–≤–µ—Ä–∫–∞ "–±–µ–∑ –¥–µ–ø–æ–∑–∏—Ç–∞"
NO_DEPOSIT_PATTERN = re.compile(r'–±–µ–∑\s+–¥–µ–ø–æ–∑–∏—Ç', re.I)

# –†–∞–π–æ–Ω - –≤ —Ö–µ—à—Ç–µ–≥–∞—Ö –∏ —Ç–µ–∫—Å—Ç–µ
DISTRICT_PATTERNS = [
    # –•–µ—à—Ç–µ–≥–∏: #–ú–∏—Ä–∑–æ_–£–ª—É–≥–±–µ–∫, #–ß–∏–ª–∞–Ω–∑–∞—Ä—Å–∫–∏–π
    re.compile(r'#([–ê-–Ø–Å–∞-—è—ë_\-]+(?:—Å–∫–∏–π|–∏–π)?)\s*(?:—Ä–∞–π–æ–Ω)?', re.I),
    # "üìç –†–∞–π–æ–Ω: –ú–∏—Ä–∑–æ –£–ª—É–≥–±–µ–∫—Å–∫–∏–π"
    re.compile(r'(?:üìç)?\s*—Ä–∞–π–æ–Ω\s*[:\-‚Äì]?\s*([–ê-–Ø–Å–∞-—è—ë\s\-]+?)(?:\s*[,\nüìçüéØ]|$)', re.I),
    # "–ú–∏—Ä–∑–æ-–£–ª—É–≥–±–µ–∫—Å–∫–∏–π —Ä–∞–π–æ–Ω"
    re.compile(r'([–ê-–Ø–Å–∞-—è—ë\-]+(?:—Å–∫–∏–π|–∏–π))\s+—Ä–∞–π–æ–Ω', re.I),
    # –£–∑–±–µ–∫—Å–∫–∏–π: "MIRZO ULUG'BEK TUMANI"
    re.compile(r"([A-Za-z'\s]+)\s+tumani", re.I),
]

# –ê–¥—Ä–µ—Å/–û—Ä–∏–µ–Ω—Ç–∏—Ä
ADDRESS_PATTERNS = [
    # "üéØ –ê–¥—Ä–µ—Å: –ñ–ö –£–∑–º–∞—Ö–∞–ª"
    re.compile(r'(?:üéØ|‚õ≥Ô∏è)?\s*(?:–∞–¥—Ä–µ—Å|manzil)\s*[:\-‚Äì]?\s*(.+?)(?:\n|$)', re.I),
    # "–û—Ä-—Ä –¢–æ—á–∫–∞ –≤–∫—É—Å–∞", "–û—Ä–∏–µ–Ω—Ç–∏—Ä: –ú–µ—Ç—Ä–æ –º–∏–Ω–æ—Ä"
    re.compile(r'(?:–æ—Ä[‚Äì\-]—Ä|–æ—Ä–∏–µ–Ω—Ç–∏—Ä|mo\'ljal)\s*[:\-‚Äì]?\s*(.+?)(?:\n|$)', re.I),
]

# –ú–µ—Ç—Ä–æ
METRO_PATTERNS = [
    re.compile(r'–º–µ—Ç—Ä–æ\s+([–ê-–Ø–Å–∞-—è—ëA-Za-z\s\']+?)(?:\s*[,\nüöäüìç]|$)', re.I),
    re.compile(r'metro\s+([A-Za-z\s\']+?)(?:\s*[,\nüöä]|$)', re.I),
]

# –ñ–ö (–∂–∏–ª–æ–π –∫–æ–º–ø–ª–µ–∫—Å)
JK_PATTERN = re.compile(r'(?:–∂–∫|jk)\s*["\']?([–ê-–Ø–Å–∞-—è—ëA-Za-z\s\-\']+)["\']?', re.I)

# –ö–æ–º–∏—Å—Å–∏—è
COMMISSION_PATTERNS = [
    re.compile(r'–∫–æ–º–∏—Å—Å?–∏–æ–Ω–Ω?—ã?–µ?\s*(\d+)?\s*%?', re.I),
    re.compile(r'maklerskiy\s*(\d+)?\s*%?', re.I),
    re.compile(r'—Ä–∏–µ–ª—Ç–æ—Ä\s*—É—Å–ª—É–≥–∏?\s*(\d+)?\s*%?', re.I),
    re.compile(r'\((\d+)\s*%\s*\)', re.I),  # (50%)
]

# –ë–µ–∑ –∫–æ–º–∏—Å—Å–∏–∏/–º–∞–∫–ª–µ—Ä–∞
NO_COMMISSION_PATTERNS = [
    re.compile(r'–±–µ–∑\s+(?:–º–∞–∫–ª–µ—Ä|–∫–æ–º–∏—Å—Å|–ø–æ—Å—Ä–µ–¥–Ω–∏–∫)', re.I),
    re.compile(r'bezmakler', re.I),
    re.compile(r'–Ω–µ\s+–¥–ª—è\s+—Ä–∏–µ–ª—Ç–æ—Ä', re.I),
]

# –°–æ—Å—Ç–æ—è–Ω–∏–µ/—Ä–µ–º–æ–Ω—Ç
CONDITION_PATTERNS = [
    re.compile(r'(?:üè∑|üî∑)?\s*—Å–æ—Å—Ç–æ—è–Ω–∏–µ\s*[:\-‚Äì]?\s*([–ê-–Ø–Å–∞-—è—ë\s]+?)(?:\s*[,\nüîπüíÆID]|$)', re.I),
    re.compile(r'(–µ–≤—Ä–æ\s*—Ä–µ–º–æ–Ω—Ç|–Ω–æ–≤—ã–π\s*—Ä–µ–º–æ–Ω—Ç|—Ö–æ—Ä–æ—à–∏–π\s*—Ä–µ–º–æ–Ω—Ç|–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π\s*—Ä–µ–º–æ–Ω—Ç)', re.I),
    re.compile(r'evro\s*ta\'?mir', re.I),
]

# –¢–∏–ø –¥–æ–º–∞
HOUSE_TYPE_PATTERNS = [
    re.compile(r'—Ç–∏–ø\s*–¥–æ–º–∞\s*[:\-‚Äì]?\s*([–ê-–Ø–Å–∞-—è—ë\s]+?)(?:\s*[,\nüîπ]|$)', re.I),
    re.compile(r'(–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞|–≤—Ç–æ—Ä–∏—á–Ω\w*(?:\s*—Ñ–æ–Ω–¥)?)', re.I),
    re.compile(r'(?:‚òëÔ∏è)?\s*(–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞|–≤—Ç–æ—Ä–∏—á–Ω\w*)', re.I),
]

# –£–¥–æ–±—Å—Ç–≤–∞ - –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
AMENITIES = {
    'has_furniture': [
        r'–º–µ–±–µ–ª[—å–∏—è]', r'–º–µ–±–ª–∏—Ä–æ–≤–∞–Ω', r'—Å\s+–º–µ–±–µ–ª—å—é',
        r'mebel', r'–¥–∏–≤–∞–Ω', r'–∫—Ä–æ–≤–∞—Ç—å', r'divan'
    ],
    'has_conditioner': [
        r'–∫–æ–Ω–¥–∏—Ü', r'—Å–ø–ª–∏—Ç', r'konditsioner', r'konditsoner'
    ],
    'has_washing_machine': [
        r'—Å—Ç–∏—Ä–∞–ª', r'—Å—Ç–∏—Ä\.?\s*–º–∞—à', r'–∫–∏—Ä–º–æ—à–∏–Ω–∞', r'kirmoshina'
    ],
    'has_refrigerator': [
        r'—Ö–æ–ª–æ–¥–∏–ª—å–Ω–∏–∫', r'muzlatgich'
    ],
    'has_internet': [
        r'–∏–Ω—Ç–µ—Ä–Ω–µ—Ç', r'wi-?fi', r'wifi'
    ],
    'has_tv': [
        r'—Ç–µ–ª–µ–≤–∏–∑–æ—Ä', r'televizor', r'—Ç–≤'
    ],
    'has_balcony': [
        r'–±–∞–ª–∫–æ–Ω', r'–ª–æ–¥–∂–∏—è', r'balkon'
    ],
}

# –ö–æ–º—É —Å–¥–∞—ë—Ç—Å—è
TENANT_PATTERNS = {
    'family': [r'—Å–µ–º—å[—è–µ]', r'oila', r'–∑–∞–≥—Å'],
    'girls': [r'–¥–µ–≤—É—à–∫', r'qizlar'],
    'guys': [r'–ø–∞—Ä–Ω', r'–±–æ–ª–ª–∞—Ä–≥–∞', r'bollar'],
    'single': [r'–æ–¥–∏–Ω–æ—á', r'–æ–¥–∏–Ω\s+–ø–∞—Ä–µ–Ω—å', r'–æ–¥–∏–Ω\s+—á–µ–ª–æ–≤–µ–∫'],
}


# ============================================
# HELPER FUNCTIONS
# ============================================

def normalize_text(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞."""
    if not text:
        return ""
    # –ó–∞–º–µ–Ω—è–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∏–¥—ã —Ç–∏—Ä–µ –∏ –ø—Ä–æ–±–µ–ª–æ–≤
    t = text.replace('\u00a0', ' ')  # non-breaking space
    t = t.replace('‚Äì', '-').replace('‚Äî', '-')
    t = re.sub(r'\s+', ' ', t)
    return t.strip()


def extract_number(text: str) -> Optional[int]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–æ –∏–∑ —Å—Ç—Ä–æ–∫–∏."""
    if not text:
        return None
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–Ω—É—Ç—Ä–∏ —á–∏—Å–ª–∞
    digits = re.sub(r'[\s\-]', '', text)
    digits = re.sub(r'\D', '', digits)
    if digits:
        try:
            return int(digits)
        except ValueError:
            pass
    return None


def extract_float(text: str) -> Optional[float]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥—Ä–æ–±–Ω–æ–µ —á–∏—Å–ª–æ."""
    if not text:
        return None
    text = text.replace(',', '.')
    match = re.search(r'(\d+(?:\.\d+)?)', text)
    if match:
        try:
            return float(match.group(1))
        except ValueError:
            pass
    return None


def match_first(patterns: List[re.Pattern], text: str) -> Optional[re.Match]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–≤–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–∑ —Å–ø–∏—Å–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤."""
    for pattern in patterns:
        match = pattern.search(text)
        if match:
            return match
    return None


def check_any_keyword(text: str, keywords: List[str]) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –ª—é–±–æ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞."""
    text_lower = text.lower()
    for kw in keywords:
        if re.search(kw, text_lower, re.I):
            return True
    return False


def normalize_district(raw: str) -> Optional[str]:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–π–æ–Ω–∞."""
    if not raw:
        return None
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
    clean = re.sub(r'[#_\-]', ' ', raw.lower()).strip()
    clean = re.sub(r'\s+', ' ', clean)
    
    # –ò—â–µ–º –≤ —Å–ª–æ–≤–∞—Ä–µ
    for key, value in DISTRICTS.items():
        if key in clean or clean in key:
            return value
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—á–∏—â–µ–Ω–Ω–æ–µ –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏
    if len(clean) > 3:
        return clean.title()
    return None


def normalize_metro(raw: str) -> Optional[str]:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω—Ü–∏–∏ –º–µ—Ç—Ä–æ."""
    if not raw:
        return None
    clean = raw.lower().strip()
    
    for key, value in METRO_STATIONS.items():
        if key in clean:
            return value
    
    if len(clean) > 2:
        return clean.title()
    return None


# ============================================
# MAIN PARSING FUNCTIONS  
# ============================================

def extract_phones(text: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã–µ –Ω–æ–º–µ—Ä–∞."""
    if not text:
        return []
    
    phones = set()
    
    # –ò—â–µ–º –ø–æ–ª–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ +998XXXXXXXXX
    full_pattern = re.compile(r'\+?998\s*[\-\(\)]?\s*(\d{2})\s*[\-\(\)]?\s*(\d{3})\s*[\-\(\)]?\s*(\d{2})\s*[\-\(\)]?\s*(\d{2})')
    for match in full_pattern.finditer(text):
        phone = '+998' + ''.join(match.groups())
        phones.add(phone)
    
    # –ò—â–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –Ω–æ–º–µ—Ä–∞ (9 —Ü–∏—Ñ—Ä –±–µ–∑ –∫–æ–¥–∞ —Å—Ç—Ä–∞–Ω—ã)
    if not phones:
        short_pattern = re.compile(r'\b(\d{2})[\s\-]?(\d{3})[\s\-]?(\d{2})[\s\-]?(\d{2})\b')
        for match in short_pattern.finditer(text):
            digits = ''.join(match.groups())
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ —É–∑–±–µ–∫—Å–∫–∏–π –Ω–æ–º–µ—Ä
            if digits[0] in '789':
                phones.add('+998' + digits)
    
    return list(phones)


def parse_triple_format(text: str) -> Tuple[Optional[int], Optional[int], Optional[int]]:
    """–ü–∞—Ä—Å–∏—Ç —Ñ–æ—Ä–º–∞—Ç X/X/X (–∫–æ–º–Ω–∞—Ç—ã/—ç—Ç–∞–∂/—ç—Ç–∞–∂–Ω–æ—Å—Ç—å)."""
    match = TRIPLE_FORMAT.search(text)
    if match:
        try:
            rooms = int(match.group(1))
            floor = int(match.group(2))
            total_floors = int(match.group(3))
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            if 0 < rooms <= 10 and 0 < floor <= 50 and 0 < total_floors <= 50:
                if floor <= total_floors:
                    return rooms, floor, total_floors
        except (ValueError, IndexError):
            pass
    return None, None, None


def parse_rooms(text: str) -> Optional[int]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç."""
    match = match_first(ROOMS_PATTERNS, text)
    if match:
        rooms = extract_number(match.group(1))
        if rooms and 0 < rooms <= 10:
            return rooms
    return None


def parse_floor(text: str) -> Tuple[Optional[int], Optional[int]]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —ç—Ç–∞–∂ –∏ —ç—Ç–∞–∂–Ω–æ—Å—Ç—å."""
    floor = None
    total_floors = None
    
    # –ò—â–µ–º —ç—Ç–∞–∂
    match = match_first(FLOOR_PATTERNS, text)
    if match:
        floor = extract_number(match.group(1))
        if floor and floor > 50:
            floor = None
    
    # –ò—â–µ–º —ç—Ç–∞–∂–Ω–æ—Å—Ç—å
    match = match_first(TOTAL_FLOORS_PATTERNS, text)
    if match:
        total_floors = extract_number(match.group(1))
        if total_floors and total_floors > 50:
            total_floors = None
    
    return floor, total_floors


def parse_area(text: str) -> Optional[float]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–ª–æ—â–∞–¥—å."""
    match = match_first(AREA_PATTERNS, text)
    if match:
        area = extract_float(match.group(1))
        if area and 5 < area < 1000:  # —Ä–∞–∑—É–º–Ω—ã–µ –ø—Ä–µ–¥–µ–ª—ã
            return area
    return None


def parse_price(text: str) -> Tuple[Optional[int], Optional[str]]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–µ–Ω—É –∏ –≤–∞–ª—é—Ç—É."""
    for pattern in PRICE_PATTERNS:
        match = pattern.search(text)
        if match:
            price = extract_number(match.group(1))
            if not price:
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–∞–ª—é—Ç—É
            currency = "usd"  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if match.lastindex >= 2 and match.group(2):
                cur_raw = match.group(2).lower()
                if any(x in cur_raw for x in ['—Å—É–º', 'sum', "so'm"]):
                    currency = "uzs"
            
            # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –±–æ–ª—å—à–∏–µ —á–∏—Å–ª–∞ —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –≤ —Å—É–º–∞—Ö
            if price > 50000:
                currency = "uzs"
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ü–µ–Ω—ã
            if currency == "usd" and 50 <= price <= 10000:
                return price, currency
            elif currency == "uzs" and price >= 100000:
                return price, currency
    
    return None, None


def parse_deposit(text: str) -> Tuple[Optional[int], bool]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–µ–ø–æ–∑–∏—Ç –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç '–±–µ–∑ –¥–µ–ø–æ–∑–∏—Ç–∞'."""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º "–±–µ–∑ –¥–µ–ø–æ–∑–∏—Ç–∞"
    if NO_DEPOSIT_PATTERN.search(text):
        return None, True
    
    # –ò—â–µ–º —Å—É–º–º—É –¥–µ–ø–æ–∑–∏—Ç–∞
    for pattern in DEPOSIT_PATTERNS:
        match = pattern.search(text)
        if match:
            deposit = extract_number(match.group(1))
            if deposit and 10 <= deposit <= 10000:
                return deposit, False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–ª–æ–≤–∞ "–¥–µ–ø–æ–∑–∏—Ç" –±–µ–∑ —Å—É–º–º—ã
    if re.search(r'–¥–µ–ø–æ–∑–∏—Ç|deposit', text, re.I):
        return None, False  # –¥–µ–ø–æ–∑–∏—Ç –µ—Å—Ç—å, –Ω–æ —Å—É–º–º–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞
    
    return None, False


def parse_district(text: str, hashtags: List[str] = None) -> Optional[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ä–∞–π–æ–Ω."""
    # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º —è–≤–Ω–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ä–∞–π–æ–Ω–∞ –≤ —Ç–µ–∫—Å—Ç–µ
    # "–ú–∏—Ä–∞–±–∞–¥—Å–∫–∏–π —Ä–∞–π–æ–Ω", "–ú–∏—Ä–∑–æ-–£–ª—É–≥–±–µ–∫—Å–∫–∏–π —Ä–∞–π–æ–Ω"
    district_mention = re.search(r'([–ê-–Ø–Å–∞-—è—ë\-]+(?:—Å–∫–∏–π|–∏–π))\s+—Ä–∞–π–æ–Ω', text, re.I)
    if district_mention:
        district = normalize_district(district_mention.group(1))
        if district:
            return district
    
    # –ò—â–µ–º —Ñ–æ—Ä–º–∞—Ç "üìç –†–∞–π–æ–Ω: –ú–∏—Ä–∑–æ –£–ª—É–≥–±–µ–∫—Å–∫–∏–π"
    district_label = re.search(r'—Ä–∞–π–æ–Ω\s*[:\-‚Äì]\s*([–ê-–Ø–Å–∞-—è—ë\s\-]+?)(?:\s*[,\nüìçüéØüè¢]|$)', text, re.I)
    if district_label:
        district = normalize_district(district_label.group(1))
        if district:
            return district
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ö–µ—à—Ç–µ–≥–∏ (–Ω–æ –Ω–µ –≤—Å–µ –ø–æ–¥—Ä—è–¥, –∞ —Ç–æ–ª—å–∫–æ –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ —Ä–∞–π–æ–Ω—ã)
    for tag in (hashtags or []):
        tag_lower = tag.lower().replace('_', ' ')
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —è–≤–Ω–æ –Ω–µ —Ä–∞–π–æ–Ω—ã
        if any(x in tag_lower for x in ['–∫–æ–º–Ω–∞—Ç', '–¥–æ–ª–ª', 'oila', 'qiz', 'boll']):
            continue
        district = normalize_district(tag)
        if district:
            return district
    
    # –ò—â–µ–º —É–∑–±–µ–∫—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç "TUMANI"
    uz_district = re.search(r"([A-Za-z'\s]+)\s+tumani", text, re.I)
    if uz_district:
        district = normalize_district(uz_district.group(1))
        if district:
            return district
    
    return None


def parse_metro(text: str) -> Optional[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç–∞–Ω—Ü–∏—é –º–µ—Ç—Ä–æ."""
    match = match_first(METRO_PATTERNS, text)
    if match:
        return normalize_metro(match.group(1))
    return None


def parse_address(text: str) -> Tuple[Optional[str], Optional[str]]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞–¥—Ä–µ—Å –∏ –æ—Ä–∏–µ–Ω—Ç–∏—Ä."""
    address = None
    landmark = None
    
    # –ò—â–µ–º –∞–¥—Ä–µ—Å
    for pattern in ADDRESS_PATTERNS:
        match = pattern.search(text)
        if match:
            raw = match.group(1).strip()
            if len(raw) > 3:
                if '–æ—Ä–∏–µ–Ω—Ç–∏—Ä' in pattern.pattern.lower() or 'mo\'ljal' in pattern.pattern.lower():
                    landmark = raw
                else:
                    address = raw
                break
    
    # –ò—â–µ–º –ñ–ö
    jk_match = JK_PATTERN.search(text)
    if jk_match:
        jk_name = jk_match.group(1).strip()
        if address:
            address = f"–ñ–ö {jk_name}, {address}"
        else:
            address = f"–ñ–ö {jk_name}"
    
    return address, landmark


def parse_commission(text: str) -> Tuple[bool, Optional[int]]:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∏ —Ä–∞–∑–º–µ—Ä –∫–æ–º–∏—Å—Å–∏–∏."""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º "–±–µ–∑ –∫–æ–º–∏—Å—Å–∏–∏"
    for pattern in NO_COMMISSION_PATTERNS:
        if pattern.search(text):
            return False, None
    
    # –ò—â–µ–º —Ä–∞–∑–º–µ—Ä –∫–æ–º–∏—Å—Å–∏–∏
    for pattern in COMMISSION_PATTERNS:
        match = pattern.search(text)
        if match:
            pct = None
            if match.lastindex and match.lastindex >= 1 and match.group(1):
                pct = extract_number(match.group(1))
            return True, pct
    
    return False, None


def parse_condition(text: str) -> Optional[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ/—Ä–µ–º–æ–Ω—Ç."""
    for pattern in CONDITION_PATTERNS:
        match = pattern.search(text)
        if match:
            cond = match.group(1).strip() if match.lastindex >= 1 else match.group(0).strip()
            if len(cond) > 2:
                return cond.lower().replace('  ', ' ')
    return None


def parse_house_type(text: str) -> Optional[str]:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –¥–æ–º–∞."""
    for pattern in HOUSE_TYPE_PATTERNS:
        match = pattern.search(text)
        if match:
            raw = match.group(1).lower().strip() if match.lastindex >= 1 else match.group(0).lower()
            if '–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞' in raw or 'novostroy' in raw:
                return "–Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞"
            if '–≤—Ç–æ—Ä–∏—á–Ω' in raw:
                return "–≤—Ç–æ—Ä–∏—á–∫–∞"
    return None


def parse_amenities(text: str) -> Dict[str, bool]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —É–¥–æ–±—Å—Ç–≤–∞."""
    result = {}
    for key, keywords in AMENITIES.items():
        result[key] = check_any_keyword(text, keywords)
    return result


def parse_tenant_type(text: str) -> List[str]:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–º—É —Å–¥–∞—ë—Ç—Å—è."""
    result = []
    for tenant_type, keywords in TENANT_PATTERNS.items():
        if check_any_keyword(text, keywords):
            result.append(tenant_type)
    return result


def detect_deal_type(text: str, hashtags: List[str] = None) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Å–¥–µ–ª–∫–∏."""
    t = text.lower()
    tags = ' '.join(h.lower() for h in (hashtags or []))
    
    # –ü–æ–∏—Å–∫ –∂–∏–ª—å—è
    if any(x in t for x in ['—Å–Ω–∏–º—É', '–∏—â—É –∫–≤–∞—Ä—Ç–∏—Ä—É', '–∏—â—É –∫–æ–º–Ω–∞—Ç—É', '–Ω—É–∂–Ω–∞ –∫–≤–∞—Ä—Ç–∏—Ä–∞']):
        return 'wanted_rent'
    if '–∫—É–ø–ª—é' in t:
        return 'wanted_buy'
    
    # –ü–æ—Å—É—Ç–æ—á–Ω–æ
    if any(x in t for x in ['–ø–æ—Å—É—Ç–æ—á–Ω–æ', '—Å—É—Ç–∫–∏', 'sutka']):
        return 'rent_daily'
    
    # –ü—Ä–æ–¥–∞–∂–∞
    if any(x in t for x in ['–ø—Ä–æ–¥–∞–º', '–ø—Ä–æ–¥–∞—é', '–ø—Ä–æ–¥–∞–∂–∞', 'sotiladi']) or '–ø—Ä–æ–¥–∞–∂–∞' in tags:
        return 'sale'
    
    # –ê—Ä–µ–Ω–¥–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    return 'rent_long'


def detect_object_type(text: str, rooms: Optional[int] = None) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –æ–±—ä–µ–∫—Ç–∞."""
    t = text.lower()
    
    if any(x in t for x in ['—Å—Ç—É–¥–∏—è', 'studio']):
        return 'studio'
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º "–∫–æ–º–Ω–∞—Ç–∞" —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ "X-–∫–æ–º–Ω–∞—Ç–Ω–∞—è –∫–≤–∞—Ä—Ç–∏—Ä–∞"
    if re.search(r'\b–∫–æ–º–Ω–∞—Ç[—É–∞]\b', t) and not re.search(r'\d+\s*[‚Äì\-]?\s*–∫–æ–º–Ω–∞—Ç', t):
        return 'room'
    
    # –î–æ–º/–∫–æ—Ç—Ç–µ–¥–∂ - –Ω–æ –Ω–µ "—Ç–∏–ø –¥–æ–º–∞", "—ç—Ç–∞–∂–µ–π –≤ –¥–æ–º–µ"
    if re.search(r'(?:–∫–æ—Ç–µ–¥–∂|–∫–æ—Ç—Ç–µ–¥–∂|—á–∞—Å—Ç–Ω—ã–π\s+–¥–æ–º|hovli)', t):
        return 'house'
    if re.search(r'\b–¥–æ–º\b', t) and not re.search(r'—Ç–∏–ø\s+–¥–æ–º–∞|–≤\s+–¥–æ–º–µ|—ç—Ç–∞–∂–µ–π\s+–≤\s+–¥–æ–º–µ', t):
        return 'house'
    
    if any(x in t for x in ['—É—á–∞—Å—Ç–æ–∫', '—Å–æ—Ç–æ–∫', 'yer']):
        return 'land'
    
    if any(x in t for x in ['–æ—Ñ–∏—Å', '–∫–æ–º–º–µ—Ä—á']):
        return 'commercial'
    
    return 'flat'


def detect_is_real_estate(text: str, hashtags: List[str] = None) -> bool:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ–º –æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏."""
    t = text.lower()
    tags = ' '.join(h.lower() for h in (hashtags or []))
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
    keywords = [
        '–∫–≤–∞—Ä—Ç–∏—Ä', '–∫–æ–º–Ω–∞—Ç', '–∞—Ä–µ–Ω–¥–∞', '—Å–¥–∞–µ—Ç—Å—è', '—Å–¥–∞—ë—Ç—Å—è', '—Å–¥–∞–º',
        '—ç—Ç–∞–∂', '–¥–µ–ø–æ–∑–∏—Ç', '–∫–æ–º–∏—Å—Å', '—Ä–∏–µ–ª—Ç–æ—Ä', '–º–∞–∫–ª–µ—Ä',
        'xona', 'ijara', 'kvartira', 'narx', 'maklerskiy'
    ]
    
    if any(k in t for k in keywords):
        return True
    
    if any(k in tags for k in ['–∞—Ä–µ–Ω–¥–∞', '–∫–≤–∞—Ä—Ç–∏—Ä–∞', 'rent']):
        return True
    
    # –§–æ—Ä–º–∞—Ç X/X/X
    if TRIPLE_FORMAT.search(text):
        return True
    
    # –¶–µ–Ω–∞ –≤ –¥–æ–ª–ª–∞—Ä–∞—Ö
    if re.search(r'\d{2,4}\s*\$', t):
        return True
    
    return False


def extract_hashtags(text: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ö–µ—à—Ç–µ–≥–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
    return re.findall(r'#([–ê-–Ø–Å–∞-—è—ëA-Za-z0-9_]+)', text)


def clean_description(text: str) -> str:
    """–°–æ–∑–¥–∞—ë—Ç —á–∏—Å—Ç–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –±–µ–∑ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö."""
    if not text:
        return ""
    
    result = text
    
    # –£–±–∏—Ä–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    patterns_to_remove = [
        r'#\S+',  # —Ö–µ—à—Ç–µ–≥–∏
        r'[‚ö´üü†üî¥üîπüî∏üíÆüìçüéØüè°üí∏üìê‚è´üîº‚ô¶Ô∏èüì£‚òéÔ∏è‚úèÔ∏èüì≤üîë‚úâÔ∏èüëâü™ß‚òëÔ∏èüîéüè∑üíµüì±üîµüìùüîó‚úÖüéñüí∞‚õ≥Ô∏èüë§üî•üíéüè¢]',  # —ç–º–æ–¥–∑–∏
        r'\+998[\d\s\-]+',  # —Ç–µ–ª–µ—Ñ–æ–Ω—ã
        r't\.me/\S+',  # —Å—Å—ã–ª–∫–∏ telegram
        r'https?://\S+',  # —Å—Å—ã–ª–∫–∏
        r'@\S+',  # —é–∑–µ—Ä–Ω–µ–π–º—ã
        r'ID\s*[:\-]?\s*\d+',  # ID –æ–±—ä—è–≤–ª–µ–Ω–∏—è
        r'\d+/\d+/\d+',  # —Ñ–æ—Ä–º–∞—Ç X/X/X
        r'–∫–æ–º–∏—Å—Å\w*\s*\d*\s*%?[^\n]*',  # –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–º–∏—Å—Å–∏–∏
        r'maklerskiy[^\n]*',
        r'—Ä–∏–µ–ª—Ç–æ—Ä[^\n]*',
    ]
    
    for pattern in patterns_to_remove:
        result = re.sub(pattern, ' ', result, flags=re.I)
    
    # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    lines = result.split('\n')
    clean_lines = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Ç–æ–ª—å–∫–æ —Å —Ü–∏—Ñ—Ä–∞–º–∏/—Å–∏–º–≤–æ–ª–∞–º–∏
        if re.match(r'^[\d\s\-\+\(\)\.,:;/\\]+$', line):
            continue
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
        if len(line) < 10:
            continue
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
        if re.match(r'^[–ê-–Ø–∞-—è–Å—ë\s]+\s*[:\-‚Äì]\s*\d+', line):
            continue
        clean_lines.append(line)
    
    result = ' '.join(clean_lines)
    result = re.sub(r'\s+', ' ', result).strip()
    
    return result if len(result) >= 20 else ""


# ============================================
# MAIN PARSER FUNCTION
# ============================================

def parse_listing(text: str, hashtags: List[str] = None) -> Dict[str, Any]:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è.
    
    Args:
        text: –°—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è
        hashtags: –°–ø–∏—Å–æ–∫ —Ö–µ—à—Ç–µ–≥–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    """
    if not text:
        return {"is_real_estate": False}
    
    text = text.strip()
    hashtags = hashtags or extract_hashtags(text)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ–º –æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
    if not detect_is_real_estate(text, hashtags):
        return {"is_real_estate": False}
    
    # –ü–∞—Ä—Å–∏–º —Ñ–æ—Ä–º–∞—Ç X/X/X
    rooms, floor, total_floors = parse_triple_format(text)
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ —Ç—Ä–æ–π–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –ø–∞—Ä—Å–∏–º –æ—Ç–¥–µ–ª—å–Ω–æ
    if rooms is None:
        rooms = parse_rooms(text)
    
    if floor is None or total_floors is None:
        f, tf = parse_floor(text)
        if floor is None:
            floor = f
        if total_floors is None:
            total_floors = tf
    
    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
    area = parse_area(text)
    price, currency = parse_price(text)
    deposit, no_deposit = parse_deposit(text)
    district = parse_district(text, hashtags)
    metro = parse_metro(text)
    address, landmark = parse_address(text)
    has_commission, commission_pct = parse_commission(text)
    condition = parse_condition(text)
    house_type = parse_house_type(text)
    amenities = parse_amenities(text)
    tenant_types = parse_tenant_type(text)
    phones = extract_phones(text)
    deal_type = detect_deal_type(text, hashtags)
    object_type = detect_object_type(text, rooms)
    description = clean_description(text)
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
    parse_score = 0
    if rooms: parse_score += 2
    if floor: parse_score += 1
    if total_floors: parse_score += 1
    if area: parse_score += 1
    if price: parse_score += 3
    if district: parse_score += 2
    if metro: parse_score += 1
    if phones: parse_score += 1
    
    return {
        "is_real_estate": True,
        
        # –¢–∏–ø —Å–¥–µ–ª–∫–∏
        "deal_type": deal_type,
        "object_type": object_type,
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—ä–µ–∫—Ç–∞
        "rooms": rooms,
        "floor": floor,
        "total_floors": total_floors,
        "area_m2": area,
        
        # –¶–µ–Ω–∞
        "price": price,
        "currency": currency,
        "price_period": "day" if deal_type == "rent_daily" else "month",
        
        # –î–µ–ø–æ–∑–∏—Ç
        "deposit": deposit,
        "no_deposit": no_deposit,
        
        # –õ–æ–∫–∞—Ü–∏—è
        "district_raw": district,
        "metro_raw": metro,
        "address_raw": address,
        "landmark": landmark,
        
        # –ö–æ–º–∏—Å—Å–∏—è
        "has_commission": has_commission,
        "commission_pct": commission_pct,
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ
        "condition": condition,
        "house_type": house_type,
        
        # –£–¥–æ–±—Å—Ç–≤–∞
        **{f"has_{k.replace('has_', '')}": v for k, v in amenities.items()},
        
        # –ö–æ–º—É —Å–¥–∞—ë—Ç—Å—è
        "tenant_types": tenant_types,
        
        # –ö–æ–Ω—Ç–∞–∫—Ç—ã
        "phones": phones,
        
        # –û–ø–∏—Å–∞–Ω–∏–µ
        "description_clean": description,
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        "parse_score": parse_score,
        "needs_review": parse_score < 5,
    }


# ============================================
# TEST
# ============================================

if __name__ == "__main__":
    test_cases = [
        """‚õ≥Ô∏è  Manzil-–ê–¥—Ä–µ—Å
–ú–ê–°–°–ò–í –Ø–õ–ê–ù–ì–ê–ß –ü–ê–†–ö –õ–û–ö–û–ú–ê–¢–ò–í 

  Xonalar-–ö–æ–º–Ω–∞—Ç—ã
‚ö´Ô∏èüü†  1/4/4  üü†‚ö´Ô∏è

üë§ Kimga-–ö–æ–º—É 
–°–µ–º—å—è –ó–ê–ì–° –∏–ª–∏ –û–¥–∏–Ω–æ—á–∫–∞ –ü–æ—Ä—è–¥–æ—á–Ω—ã–µ

üí∞ Narx-–¶–µ–Ω–∞: 350$+300$ –î–µ–ø–æ–∑–∏—Ç 

üéñ Maklerskiy-–ö–æ–º–º–∏—Å–∏—è  (50%)

‚òéÔ∏è Tel: 903335552

#–ú–∏—Ä–∑–æ_–£–ª—É–≥–±–µ–∫      #2979""",

        """#–ß–∏–ª–∞–Ω–∑–∞—Ä—Å–∫–∏–π —Ä–∞–π–æ–Ω,7-–∫–≤–∞—Ä—Ç–∞–ª
–û—Ä-—Ä Hi-Tech –ú–µ—á–µ—Ç—å
üîπ–¢–∏–ø –¥–æ–º–∞:–í—Ç–æ—Ä–∏—á–Ω—ã–π —Ñ–æ–Ω–¥
üîπ–ö–æ–ª-–≤–æ –∫–æ–º–Ω–∞—Ç: 2*3
üîπ–≠—Ç–∞–∂: 
üîπ–≠—Ç–∞–∂–Ω–æ—Å—Ç—å: 4
üîπ–ü–ª–æ—â–∞–¥—å –∫–≤.–º–µ—Ç—Ä:55
üîπ–¶–µ–Ω–∞: 600$ 
üî∑–°–æ—Å—Ç–æ—è–Ω–∏–µ:–ï–≤—Ä–æ—Ä–µ–º–æ–Ω—Ç 
ID:12399
–ö–æ–º–∏—Å—Å–∏–æ–Ω–Ω—ã–µ 50% –æ—Ç –ø–µ—Ä–≤–æ–≥–æ –º–µ—Å—è—Ü–∞""",

        """üü£–ú–∏—Ä–∞–±–∞–¥—Å–∫–∏–π —Ä–∞–π–æ–Ω
     –ù–æ–≤–æ—Å—Ç—Ä–æ–π–∫–∞ 
     –ü—Ä–µ–º–∏—É–º –∫–ª–∞—Å—Å–∞
    –ñ–ö Mirabad avenue

üì±–û—Ä–∏–µ–Ω—Ç–∏—Ä: –ú–∏—Ä–∞–±–∞–¥—Å–∫–∏–π —Ä—ã–Ω–æ–∫

üî∏–ö–æ–º–Ω–∞—Ç: 2
üî∏–≠—Ç–∞–∂: 6
üî∏–≠—Ç–∞–∂–µ–π –≤ –¥–æ–º–µ: 13
üî∏–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å: 55 –º¬≤ 

–¶–µ–Ω–∞: 1000 

üîó@Tasha16 | +998903257308""",

        """IJARAGA KVARTIRA ‚úÖ
TARTIBLI INSONLARGA ‚úÖ
#OILAGA | #QIZLARGA | #BOLLARGA ‚úÖ

Manzil: MIRZO ULUG'BEK TUMANI, QORASUV-6

Xonalar soni: 1 XONA 3/3

Sharoiti: KIRMOSHINA, KONDITSIONER, MUZLATGICH, TELEVIZOR

Narx: 350 $

Tel.: üìû +998937576775 EGASI ‚úÖ

BEZMAKLER ‚úÖ""",
    ]
    
    for i, text in enumerate(test_cases, 1):
        print(f"\n{'='*60}")
        print(f"–¢–ï–°–¢ {i}:")
        print('='*60)
        
        result = parse_listing(text)
        
        for key, value in result.items():
            if value is not None and value != "" and value != False and value != []:
                print(f"  {key}: {value}")